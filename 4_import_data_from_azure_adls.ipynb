{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Required Packages (Add under Advanced Options > Packages):\n",
        "\n",
        "'''\n",
        "org.apache.spark:spark-hadoop-cloud_2.12:3.5.1\n",
        "org.apache.hadoop:hadoop-azure:3.3.2\n",
        "org.apache.hadoop:hadoop-azure-datalake:3.3.2\n",
        "'''"
      ],
      "metadata": {
        "id": "iru-ISCgX8jI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "metadata": {
        "id": "wHiC4_qtAc0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWPcpqmoUnAz"
      },
      "outputs": [],
      "source": [
        "# Configure Your ADLS Secrets (Add under Secrets -> Workspaces -> New Secret -> Secret Type = Environment Variable)\n",
        "\n",
        "access_key=os.getenv('adls_accesskey')\n",
        "secret_key=os.getenv('adls_secretkey')\n",
        "\n",
        "spark.conf.set(\"spark.hadoop.fs.azure.account.oauth2.client.id.yeedudatabricks.dfs.core.windows.net\", access_key)\n",
        "spark.conf.set(\"spark.hadoop.fs.azure.account.oauth2.client.secret.yeedudatabricks.dfs.core.windows.net\", secret_key)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure the rest of the Credentials\n",
        "\n",
        "spark.conf.set(\"spark.hadoop.fs.azure.account.auth.type.yeedudatabricks.dfs.core.windows.net\", \"OAuth\")\n",
        "spark.conf.set(\"spark.hadoop.fs.azure.account.oauth.provider.type.yeedudatabricks.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
        "spark.conf.set(\"spark.hadoop.fs.azure.account.oauth2.client.endpoint.yeedudatabricks.dfs.core.windows.net\", \"https://login.microsoftonline.com/fdcf6fad-c3f0-4c66-8ca1-1e3aaac65150/oauth2/v2.0/token\")\n",
        "spark.conf.set(\"spark.hadoop.fs.azure.subscription.id\", \"18e47609-8677-4f80-8229-6ad33923b6ec\")\n",
        "spark.conf.set(\"spark.hadoop.fs.azure.resource.group\", \"yeedu\")\n",
        "\n",
        "# Alternatively, you can set these key-value pairs in the notebook in:\n",
        "# Advanced Options > Configs\n"
      ],
      "metadata": {
        "id": "5Pd2le55AjUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Writing and Reading Data from ADLS\n",
        "\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
        "\n",
        "data = [(\"Alice\", 30), (\"Bob\", 25), (\"Cathy\", 27)]\n",
        "schema = StructType([\n",
        "    StructField(\"Name\", StringType(), True),\n",
        "    StructField(\"Age\", IntegerType(), True)\n",
        "])\n",
        "df = spark.createDataFrame(data, schema)\n",
        "\n",
        "# Define ADLS path\n",
        "output_path = \"abfss://<insert-adls-path>\"\n",
        "\n",
        "# Write DataFrame to ADLS\n",
        "df.write.mode(\"overwrite\").parquet(output_path)\n",
        "\n",
        "# Read DataFrame from ADLS\n",
        "df_read = spark.read.parquet(output_path)\n",
        "df_read.show()"
      ],
      "metadata": {
        "id": "YqfqXEV2Aw95"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}